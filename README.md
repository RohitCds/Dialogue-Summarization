# Dialogue-Summarization

Developed an advanced NLP model for dialogue summarization, leveraging the google/flan-t5-
base model.
Employed Python, PyTorch, Transformers, and other tools for model training and evaluation.
Processed and prepared data from the dialogsum dataset, optimizing it for summarization tasks.
Implemented Parameter-Efficient Fine-Tuning (PEFT) using LoRA to enhance model performance
efficiently.
Applied Proximal Policy Optimization (PPO) in reinforcement learning to improve summarization
quality and reduce output toxicity.
Integrated a toxicity detection model (facebook/roberta-hate-speech-dynabench-r4-target)
to ensure ethical AI practices.
Achieved significant improvements in summarization accuracy, demonstrated by enhanced
ROUGE scores.
Successfully reduced the toxicity levels in the model'
s outputs, contributing to safer and more
responsible AI applications.
